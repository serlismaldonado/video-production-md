#!/usr/bin/env python3
"""
Script para an√°lisis de guiones usando LLMs.
Analiza estructura, personajes, di√°logo, ritmo y genera sugerencias.
"""

import argparse
import re
import sys
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, Optional

# Configuraci√≥n para diferentes proveedores de LLM
LLM_CONFIG = {
    "openai": {
        "api_key_env": "OPENAI_API_KEY",
        "model": "gpt-4",
        "temperature": 0.7,
    },
    "anthropic": {
        "api_key_env": "ANTHROPIC_API_KEY",
        "model": "claude-3-sonnet-20240229",
        "temperature": 0.7,
    },
    "local": {
        "api_key_env": None,
        "model": "local",
        "temperature": 0.7,
    },
}


class ScriptAnalyzer:
    """Analizador de guiones en formato markdown."""

    def __init__(self, script_path: Path, llm_provider: str = "openai"):
        self.script_path = script_path
        self.llm_provider = llm_provider
        self.script_content = ""
        self.metadata = {}
        self.analysis_results = {}

        # Verificar que el archivo exista
        if not script_path.exists():
            raise FileNotFoundError(f"Archivo no encontrado: {script_path}")

    def load_script(self) -> bool:
        """Cargar contenido del guion."""
        try:
            with open(self.script_path, "r", encoding="utf-8") as f:
                self.script_content = f.read()
            return True
        except Exception as e:
            print(f"‚ùå Error cargando guion: {e}")
            return False

    def extract_metadata(self) -> Dict[str, Any]:
        """Extraer metadatos del guion."""
        metadata = {
            "title": "Desconocido",
            "version": "1.0",
            "author": "Desconocido",
            "format": "Cortometraje",
            "estimated_duration": 0,
            "pages": 0,
            "scenes": 0,
            "characters": [],
            "locations": [],
        }

        # Buscar informaci√≥n en encabezados
        title_match = re.search(r"# GUION - (.+)", self.script_content)
        if title_match:
            metadata["title"] = title_match.group(1).strip()

        # Buscar versi√≥n
        version_match = re.search(r"## Versi√≥n (\d+\.\d+)", self.script_content)
        if version_match:
            metadata["version"] = version_match.group(1)

        # Buscar autor
        author_match = re.search(r"- \*\*Autor\*\*: (.+)", self.script_content)
        if author_match:
            metadata["author"] = author_match.group(1).strip()

        # Buscar formato
        format_match = re.search(r"- \*\*Formato\*\*: (.+)", self.script_content)
        if format_match:
            metadata["format"] = format_match.group(1).strip()

        # Buscar duraci√≥n
        duration_match = re.search(
            r"- \*\*Duraci√≥n estimada\*\*: (.+)", self.script_content
        )
        if duration_match:
            try:
                metadata["estimated_duration"] = int(
                    duration_match.group(1).strip().split()[0]
                )
            except Exception:
                pass

        # Contar escenas
        scenes = re.findall(r"## ESCENA \d+", self.script_content)
        metadata["scenes"] = len(scenes)

        # Extraer personajes
        characters_section = re.search(
            r"### PERSONAJES PRINCIPALES\n(.+?)(?:\n###|\n---)",
            self.script_content,
            re.DOTALL,
        )
        if characters_section:
            lines = characters_section.group(1).strip().split("\n")
            metadata["characters"] = [
                line.strip().replace("- ", "").replace("* ", "")
                for line in lines
                if line.strip() and not line.strip().startswith("#")
            ]

        # Extraer locaciones
        locations = set()
        location_matches = re.findall(r"\*\*INT\./EXT\. (.+?) -", self.script_content)
        for match in location_matches:
            locations.add(match.strip())
        metadata["locations"] = list(locations)

        # Estimar p√°ginas (aproximado: 1 p√°gina = 55 l√≠neas de guion)
        lines = self.script_content.split("\n")
        dialogue_lines = sum(
            1 for line in lines if re.match(r"^\*\*.+\*\*$", line.strip())
        )
        metadata["pages"] = max(1, dialogue_lines // 55)

        self.metadata = metadata
        return metadata

    def analyze_structure(self) -> Dict[str, Any]:
        """Analizar estructura narrativa."""
        structure = {
            "act_breaks": [],
            "scene_lengths": [],
            "dialogue_ratio": 0,
            "action_ratio": 0,
            "pacing": "medio",
        }

        # Dividir en escenas
        scenes = re.split(r"## ESCENA \d+", self.script_content)[1:]

        if not scenes:
            return structure

        # Calcular longitud de escenas
        scene_lengths = []
        for scene in scenes:
            lines = scene.strip().split("\n")
            scene_lengths.append(len(lines))

        structure["scene_lengths"] = scene_lengths

        # Calcular proporci√≥n di√°logo/acci√≥n
        total_lines = sum(scene_lengths)
        if total_lines > 0:
            dialogue_lines = 0
            action_lines = 0

            for line in self.script_content.split("\n"):
                line = line.strip()
                if re.match(r"^\*\*.+\*\*$", line):  # Di√°logo
                    dialogue_lines += 1
                elif line and not line.startswith("#"):  # Acci√≥n/descripci√≥n
                    action_lines += 1

            structure["dialogue_ratio"] = (
                dialogue_lines / (dialogue_lines + action_lines) * 100
            )
            structure["action_ratio"] = (
                action_lines / (dialogue_lines + action_lines) * 100
            )

        # Determinar ritmo basado en longitud de escenas
        avg_scene_length = sum(scene_lengths) / len(scene_lengths)
        if avg_scene_length < 15:
            structure["pacing"] = "r√°pido"
        elif avg_scene_length > 30:
            structure["pacing"] = "lento"
        else:
            structure["pacing"] = "medio"

        return structure

    def analyze_characters(self) -> Dict[str, Any]:
        """Analizar personajes y di√°logo."""
        characters = {}

        # Extraer todo el di√°logo - solo l√≠neas que comienzan con ** y terminan antes de otro ** o l√≠nea vac√≠a
        # Excluir cabeceras de escena que tambi√©n usan **
        dialogue_pattern = (
            r"^\*\*([A-Z√Å√â√ç√ì√ö√ë\s]+(?:\([^)]+\))?)\*\*\s*\n(.+?)(?=\n\*\*|\n\n|$)"
        )
        dialogues = re.findall(
            dialogue_pattern, self.script_content, re.MULTILINE | re.DOTALL
        )

        for character, dialogue in dialogues:
            character = character.strip()
            if character not in characters:
                characters[character] = {
                    "dialogue_count": 0,
                    "total_words": 0,
                    "average_words": 0,
                    "scenes": set(),
                }

            characters[character]["dialogue_count"] += 1
            words = len(dialogue.strip().split())
            characters[character]["total_words"] += words

        # Calcular promedios
        for char in characters:
            if characters[char]["dialogue_count"] > 0:
                characters[char]["average_words"] = (
                    characters[char]["total_words"] / characters[char]["dialogue_count"]
                )

        # Ordenar por cantidad de di√°logo
        sorted_chars = sorted(
            characters.items(),
            key=lambda x: x[1]["dialogue_count"],
            reverse=True,
        )

        return {
            "character_count": len(characters),
            "main_characters": sorted_chars[:5]
            if len(sorted_chars) >= 5
            else sorted_chars,
            "dialogue_distribution": {
                char: data["dialogue_count"] for char, data in sorted_chars
            },
            "character_analysis": characters,
        }

    def analyze_dialogue(self) -> Dict[str, Any]:
        """Analizar calidad del di√°logo."""
        dialogue_analysis = {
            "average_words_per_line": 0,
            "longest_dialogue": {"character": "", "words": 0, "text": ""},
            "shortest_dialogue": {"character": "", "words": 1000, "text": ""},
            "unique_words": set(),
            "readability_score": 0,
        }

        # Extraer di√°logo - solo l√≠neas que comienzan con ** y terminan antes de otro ** o l√≠nea vac√≠a
        # Excluir cabeceras de escena que tambi√©n usan **
        dialogue_pattern = (
            r"^\*\*([A-Z√Å√â√ç√ì√ö√ë\s]+(?:\([^)]+\))?)\*\*\s*\n(.+?)(?=\n\*\*|\n\n|$)"
        )
        dialogues = re.findall(
            dialogue_pattern, self.script_content, re.MULTILINE | re.DOTALL
        )

        if not dialogues:
            return dialogue_analysis

        total_words = 0
        total_lines = 0

        for character, dialogue in dialogues:
            character = character.strip()
            dialogue_text = dialogue.strip()
            words = len(dialogue_text.split())

            total_words += words
            total_lines += 1

            # Actualizar palabras √∫nicas
            dialogue_analysis["unique_words"].update(dialogue_text.lower().split())

            # Verificar di√°logo m√°s largo
            if words > dialogue_analysis["longest_dialogue"]["words"]:
                dialogue_analysis["longest_dialogue"] = {
                    "character": character,
                    "words": words,
                    "text": dialogue_text[:100]
                    + ("..." if len(dialogue_text) > 100 else ""),
                }

            # Verificar di√°logo m√°s corto (excluyendo muy cortos)
            if 0 < words < dialogue_analysis["shortest_dialogue"]["words"]:
                dialogue_analysis["shortest_dialogue"] = {
                    "character": character,
                    "words": words,
                    "text": dialogue_text,
                }

        # Calcular promedios
        if total_lines > 0:
            dialogue_analysis["average_words_per_line"] = total_words / total_lines

        # Calcular puntuaci√≥n de legibilidad simple
        if total_words > 0:
            # F√≥rmula simplificada: menos palabras por l√≠nea = m√°s legible
            words_per_line = total_words / total_lines
            if words_per_line < 8:
                dialogue_analysis["readability_score"] = 90
            elif words_per_line < 12:
                dialogue_analysis["readability_score"] = 70
            elif words_per_line < 16:
                dialogue_analysis["readability_score"] = 50
            else:
                dialogue_analysis["readability_score"] = 30

        return dialogue_analysis

    def generate_llm_analysis(
        self, analysis_type: str = "comprehensive"
    ) -> Optional[str]:
        """Generar an√°lisis usando LLM (placeholder - implementar seg√∫n API)."""
        # Este es un placeholder. En una implementaci√≥n real, se conectar√≠a a una API de LLM.

        prompts = {
            "comprehensive": f"""
Analiza el siguiente guion y proporciona feedback detallado:

T√çTULO: {self.metadata.get("title", "Desconocido")}
AUTOR: {self.metadata.get("author", "Desconocido")}
FORMATO: {self.metadata.get("format", "Cortometraje")}
DURACI√ìN: {self.metadata.get("estimated_duration", 0)} minutos
ESCENAS: {self.metadata.get("scenes", 0)}
PERSONAJES: {", ".join(self.metadata.get("characters", []))}

Por favor analiza:
1. ESTRUCTURA: ¬øTiene un arco narrativo claro? ¬øLos puntos de giro son efectivos?
2. PERSONAJES: ¬øSon cre√≠bles? ¬øTienen motivaciones claras?
3. DI√ÅLOGO: ¬øSuena natural? ¬øRevela car√°cter?
4. RITMO: ¬øEl pacing es apropiado para el g√©nero?
5. FORMATO: ¬øSigue convenciones est√°ndar de guion?
6. SUGERENCIAS: 3-5 sugerencias espec√≠ficas para mejorar.

Responde en espa√±ol.
""",
            "character_focus": """
Analiza espec√≠ficamente los personajes del guion:
1. Arcos de personaje
2. Motivaciones y conflictos
3. Di√°logo caracterizador
4. Desarrollo a lo largo de la historia
""",
            "structure_focus": """
Analiza espec√≠ficamente la estructura del guion:
1. Tres actos y puntos de giro
2. Tensi√≥n dram√°tica
3. Ritmo y pacing
4. Resoluci√≥n satisfactoria
""",
        }

        prompt = prompts.get(analysis_type, prompts["comprehensive"])

        # En una implementaci√≥n real, aqu√≠ se har√≠a la llamada a la API
        # Por ahora, retornamos un mensaje indicando que se necesita configuraci√≥n
        return f"""
‚ö†Ô∏è  AN√ÅLISIS CON LLM (CONFIGURACI√ìN REQUERIDA)

Para usar an√°lisis con LLM, configura tu API key:

1. Para OpenAI: export OPENAI_API_KEY='tu-api-key'
2. Para Anthropic: export ANTHROPIC_API_KEY='tu-api-key'

Luego implementa la llamada a la API en generate_llm_analysis().

Prompt que se enviar√≠a:
{prompt[:500]}...
"""

    def generate_report(self, include_llm: bool = False) -> str:
        """Generar reporte completo de an√°lisis."""

        # Realizar an√°lisis
        metadata = self.extract_metadata()
        structure = self.analyze_structure()
        characters = self.analyze_characters()
        dialogue = self.analyze_dialogue()

        # Generar reporte
        report = []
        report.append("# üìä AN√ÅLISIS DE GUION")
        report.append(f"**Archivo**: {self.script_path.name}")
        report.append(
            f"**Fecha de an√°lisis**: {datetime.now().strftime('%Y-%m-%d %H:%M')}"
        )
        report.append("")

        report.append("## üìã METADATOS")
        report.append(f"- **T√≠tulo**: {metadata['title']}")
        report.append(f"- **Autor**: {metadata['author']}")
        report.append(f"- **Versi√≥n**: {metadata['version']}")
        report.append(f"- **Formato**: {metadata['format']}")
        report.append(
            f"- **Duraci√≥n estimada**: {metadata['estimated_duration']} minutos"
        )
        report.append(f"- **P√°ginas estimadas**: {metadata['pages']}")
        report.append(f"- **N√∫mero de escenas**: {metadata['scenes']}")
        report.append(f"- **Locaciones**: {', '.join(metadata['locations'][:5])}")
        if len(metadata["locations"]) > 5:
            report.append(f"  (y {len(metadata['locations']) - 5} m√°s)")
        report.append("")

        report.append("## üé≠ PERSONAJES")
        report.append(f"- **Total de personajes**: {characters['character_count']}")
        report.append("")
        report.append("### Personajes principales (por di√°logo):")
        for i, (char, data) in enumerate(characters["main_characters"], 1):
            report.append(
                f"{i}. **{char}**: {data['dialogue_count']} l√≠neas de di√°logo"
            )
        report.append("")

        report.append("## üèóÔ∏è ESTRUCTURA")
        report.append(f"- **Ritmo**: {structure['pacing'].capitalize()}")
        report.append(
            f"- **Proporci√≥n di√°logo/acci√≥n**: {structure['dialogue_ratio']:.1f}% / {structure['action_ratio']:.1f}%"
        )
        report.append(
            f"- **Longitud promedio de escenas**: {sum(structure['scene_lengths']) / len(structure['scene_lengths']):.1f} l√≠neas"
        )
        report.append("")

        report.append("### Distribuci√≥n de longitud de escenas:")
        if structure["scene_lengths"]:
            avg = sum(structure["scene_lengths"]) / len(structure["scene_lengths"])
            min_len = min(structure["scene_lengths"])
            max_len = max(structure["scene_lengths"])
            report.append(f"- **M√°s corta**: {min_len} l√≠neas")
            report.append(f"- **M√°s larga**: {max_len} l√≠neas")
            report.append(f"- **Promedio**: {avg:.1f} l√≠neas")
        report.append("")

        report.append("## üí¨ DI√ÅLOGO")
        report.append(
            f"- **Palabras por l√≠nea (promedio)**: {dialogue['average_words_per_line']:.1f}"
        )
        report.append(
            f"- **Puntuaci√≥n de legibilidad**: {dialogue['readability_score']}/100"
        )
        report.append(f"- **Palabras √∫nicas**: {len(dialogue['unique_words'])}")
        report.append("")

        if dialogue["longest_dialogue"]["words"] > 0:
            report.append("### Di√°logo m√°s largo:")
            report.append(
                f"- **Personaje**: {dialogue['longest_dialogue']['character']}"
            )
            report.append(f"- **Palabras**: {dialogue['longest_dialogue']['words']}")
            report.append(f'- **Texto**: "{dialogue["longest_dialogue"]["text"]}"')
            report.append("")

        report.append("## üìà ESTAD√çSTICAS CLAVE")
        report.append("```")
        report.append(
            f"Escenas por p√°gina: {metadata['scenes'] / max(1, metadata['pages']):.1f}"
        )
        report.append(
            f"Di√°logo por personaje (promedio): {sum(c[1]['dialogue_count'] for c in characters['main_characters']) / max(1, characters['character_count']):.1f} l√≠neas"
        )

        # Calcular densidad de di√°logo
        if metadata["pages"] > 0:
            total_dialogue = sum(
                c[1]["dialogue_count"] for c in characters["main_characters"]
            )
            report.append(
                f"Densidad de di√°logo: {total_dialogue / metadata['pages']:.1f} l√≠neas por p√°gina"
            )
            report.append("```")
            report.append("")

            report.append("## üí° RECOMENDACIONES")
            report.append("")

            # Recomendaciones basadas en an√°lisis
            recommendations = []

            # Recomendaciones de estructura
            if structure["pacing"] == "r√°pido" and metadata["pages"] > 30:
                recommendations.append(
                    "Considera desarrollar m√°s las escenas clave para mayor impacto emocional"
                )
            elif structure["pacing"] == "lento" and metadata["pages"] < 20:
                recommendations.append(
                    "Podr√≠as acelerar el ritmo eliminando o combinando escenas menos importantes"
                )

            # Recomendaciones de di√°logo
            if dialogue["average_words_per_line"] > 15:
                recommendations.append(
                    "El di√°logo es bastante largo. Considera dividir l√≠neas largas para mayor naturalidad"
                )
            elif dialogue["average_words_per_line"] < 5:
                recommendations.append(
                    "El di√°logo es muy breve. Aseg√∫rate de que los personajes se expresen completamente"
                )

            # Recomendaciones de personajes
            if characters["character_count"] > 8 and metadata["pages"] < 30:
                recommendations.append(
                    "Muchos personajes para pocas p√°ginas. Considera fusionar o eliminar algunos"
                )
            elif characters["character_count"] < 3 and metadata["pages"] > 50:
                recommendations.append(
                    "Pocos personajes para muchas p√°ginas. Podr√≠as desarrollar personajes secundarios"
                )

            # Recomendaciones de formato
            if metadata["scenes"] / max(1, metadata["pages"]) > 3:
                recommendations.append(
                    "Alta densidad de escenas. Verifica que cada escena sea necesaria y contribuya a la historia"
                )
            elif metadata["scenes"] / max(1, metadata["pages"]) < 1:
                recommendations.append(
                    "Baja densidad de escenas. Considera si algunas escenas podr√≠an dividirse para mayor claridad"
                )

            # A√±adir recomendaciones al reporte
            if recommendations:
                for i, rec in enumerate(recommendations, 1):
                    report.append(f"{i}. {rec}")
            else:
                report.append(
                    "El guion tiene buenas proporciones estructurales. Contin√∫a desarrollando seg√∫n tu visi√≥n creativa."
                )
            report.append("")

            # An√°lisis LLM si se solicita
            if include_llm:
                report.append("## ü§ñ AN√ÅLISIS CON LLM")
                report.append("")
                llm_analysis = self.generate_llm_analysis()
                report.append(llm_analysis)
                report.append("")

            report.append("## üìÅ ARCHIVOS RELACIONADOS")
            report.append(f"- **Guion analizado**: `{self.script_path}`")
            report.append(
                f"- **Metadatos de producci√≥n**: `{self.script_path.parent.parent.parent}/metadata.yaml`"
            )
            report.append(
                f"- **Concepto creativo**: `{self.script_path.parent.parent.parent}/01-preproduccion/concept.md`"
            )
            report.append("")

            report.append("## üîÑ PR√ìXIMOS PASOS SUGERIDOS")
            report.append("1. Revisar las recomendaciones espec√≠ficas para tu guion")
            report.append("2. Compartir el an√°lisis con el equipo creativo")
            report.append("3. Actualizar el guion basado en el feedback")
            report.append("4. Documentar cambios en el historial de versiones")
            report.append("5. Realizar nuevo an√°lisis despu√©s de las revisiones")
            report.append("")

            report.append("---")
            report.append(
                f"*An√°lisis generado autom√°ticamente el {datetime.now().strftime('%Y-%m-%d')}*"
            )
            report.append(
                "*Usa `python scripts/analyze-script.py --help` para m√°s opciones*"
            )

        return "\n".join(report)

    def save_report(self, report: str, output_path: Optional[Path] = None) -> Path:
        """Guardar reporte de an√°lisis."""

        if output_path is None:
            # Crear nombre de archivo basado en el guion
            script_name = self.script_path.stem
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_path = (
                self.script_path.parent / f"analysis_{script_name}_{timestamp}.md"
            )

        try:
            with open(output_path, "w", encoding="utf-8") as f:
                f.write(report)
            return output_path
        except Exception as e:
            print(f"‚ùå Error guardando reporte: {e}")
            raise


def main():
    """Funci√≥n principal."""

    parser = argparse.ArgumentParser(
        description="Analizador de guiones en formato markdown"
    )
    parser.add_argument("script", help="Ruta al archivo de guion (.md)")
    parser.add_argument(
        "--output", "-o", help="Ruta de salida para el reporte (opcional)"
    )
    parser.add_argument(
        "--llm",
        action="store_true",
        help="Incluir an√°lisis con LLM (requiere configuraci√≥n)",
    )
    parser.add_argument(
        "--provider",
        choices=["openai", "anthropic", "local"],
        default="openai",
        help="Proveedor de LLM a usar",
    )

    args = parser.parse_args()

    print("üìä Analizador de Guiones")
    print("=" * 50)

    try:
        # Crear analizador
        analyzer = ScriptAnalyzer(Path(args.script), args.provider)

        # Cargar guion
        print(f"üìñ Cargando guion: {args.script}")
        if not analyzer.load_script():
            return 1

        # Extraer metadatos
        print("üîç Extrayendo metadatos...")
        metadata = analyzer.extract_metadata()
        print(f"   ‚Ä¢ T√≠tulo: {metadata['title']}")
        print(f"   ‚Ä¢ Autor: {metadata['author']}")
        print(f"   ‚Ä¢ Escenas: {metadata['scenes']}")
        print(f"   ‚Ä¢ Personajes: {len(metadata['characters'])}")

        # Generar reporte
        print("\nüìà Generando an√°lisis...")
        report = analyzer.generate_report(include_llm=args.llm)

        # Guardar reporte
        output_path = analyzer.save_report(
            report, Path(args.output) if args.output else None
        )
        print(f"\n‚úÖ Reporte guardado: {output_path}")

        # Mostrar resumen
        print("\nüìã RESUMEN DEL AN√ÅLISIS")
        print("-" * 40)

        # An√°lisis de estructura
        structure = analyzer.analyze_structure()
        print(f"Ritmo: {structure['pacing'].capitalize()}")
        print(
            f"Di√°logo/Acci√≥n: {structure['dialogue_ratio']:.1f}% / {structure['action_ratio']:.1f}%"
        )

        # An√°lisis de personajes
        characters = analyzer.analyze_characters()
        print(f"Personajes principales: {len(characters['main_characters'])}")

        # An√°lisis de di√°logo
        dialogue = analyzer.analyze_dialogue()
        print(f"Legibilidad: {dialogue['readability_score']}/100")

        print(f"\nüìÑ Ver reporte completo: {output_path}")

        return 0

    except FileNotFoundError as e:
        print(f"‚ùå {e}")
        return 1
    except Exception as e:
        print(f"‚ùå Error inesperado: {e}")
        return 1


if __name__ == "__main__":
    try:
        sys.exit(main())
    except KeyboardInterrupt:
        print("\n\n‚ùå Operaci√≥n cancelada por el usuario.")
        sys.exit(1)
